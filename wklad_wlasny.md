# WkÅ‚ad WÅ‚asny w Projekt (Project Contributions)

Dokument ten precyzyjnie rozrÃ³Å¼nia elementy "gotowe" (zaimportowane biblioteki/modele) od elementÃ³w **zbudowanych od podstaw** w ramach tego projektu.

## 1. Model i Architektura

| Element | Status | Opis |
| :--- | :--- | :--- |
| **Encoder (ResNet-34)** | ğŸŸ¡ Gotowy (Import) | UÅ¼ywamy `torchvision.models.resnet34` z wagami ImageNet. To jest "klocki", ktÃ³ry wziÄ™liÅ›my z pÃ³Å‚ki. |
| **Adaptacja Encodera** | ğŸŸ¢ **WÅ‚asna implementacja** | Standardowy ResNet przyjmuje 3 kanaÅ‚y (RGB). My musieliÅ›my **rÄ™cznie zmodyfikowaÄ‡** pierwszÄ… warstwÄ™ konwolucyjnÄ… (`conv1`), aby przyjmowaÅ‚a 1 kanaÅ‚ (L) i zachowaÅ‚a wiedzÄ™ z treningu. WymagaÅ‚o to napisania kodu uÅ›redniajÄ…cego wagi oryginalnej warstwy. |
| **Decoder (U-Net)** | ğŸŸ¢ **WÅ‚asna implementacja** | Nie uÅ¼yliÅ›my gotowej biblioteki typu `unet_pytorch`. CaÅ‚a struktura dekodera (warstwy `up1`, `up2`..., upsampling, konkatenacja) zostaÅ‚a **zbudowana rÄ™cznie, warstwa po warstwie** w `src/model.py`, aby idealnie pasowaÄ‡ wymiarami do Encodera ResNet. |
| **Skip Connections** | ğŸŸ¢ **WÅ‚asna implementacja** | Logika Å‚Ä…czenia cech z Encodera do Dekodera (np. `torch.cat([u4, l3], dim=1)`) zostaÅ‚a napisana rÄ™cznie. To my decydujemy, ktÃ³re warstwy siÄ™ Å‚Ä…czÄ…. |
| **Refinement Block** | ğŸŸ¢ **WÅ‚asna inwencja** | Autorski moduÅ‚ dodany na koÅ„cu sieci, wykorzystujÄ…cy konwolucje atrous (dilated) do poprawy jakoÅ›ci detali. Nie jest to standardowy element U-Net. |

## 2. Funkcja Straty (Loss) i Uczenie

| Element | Status | Opis |
| :--- | :--- | :--- |
| **Loss Function** | ğŸŸ¢ **WÅ‚asna implementacja** | Nie uÅ¼ywamy standardowego `CrossEntropyLoss` z PyTorch "prosto z pudeÅ‚ka". ZaimplementowaliÅ›my wÅ‚asnÄ… klasÄ™ `MultinomialCrossEntropyLoss`, ktÃ³ra obsÅ‚uguje: <br>1. MiÄ™kkie targety (nie one-hot encoding).<br>2. WaÅ¼enie kaÅ¼dego piksela z osobna na podstawie rzadkoÅ›ci koloru. |
| **Class Rebalancing** | ğŸŸ¢ **WÅ‚asna implementacja** | Algorytm obliczania wag dla klas (`compute_loss_weights`) nie jest importem. To rÄ™cznie przepisana logika matematyczna z paperu Zhanga, ktÃ³ra miesza rozkÅ‚ad prawdopodobieÅ„stwa z rozkÅ‚adem jednostajnym. |

## 3. Dane i Pipeline (Data Engineering)

| Element | Status | Opis |
| :--- | :--- | :--- |
| **Åadowanie Danych** | ğŸŸ¢ **WÅ‚asna implementacja** | Nie uÅ¼ywamy standardowego `ImageFolder`. ZbudowaliÅ›my od zera klasÄ™ `ColorizationIterableDataset`, ktÃ³ra implementuje logikÄ™ **streamingu** danych z duÅ¼ych plikÃ³w `.npz` (shards), zamiast czytaÄ‡ miliony maÅ‚ych plikÃ³w JPG. |
| **Przygotowanie Danych** | ğŸŸ¢ **WÅ‚asna implementacja** | Skrypt `prepare_data.py` to w caÅ‚oÅ›ci nasz kod inÅ¼ynieryjny. ObsÅ‚uguje wielowÄ…tkowe (multiprocessing) przetwarzanie obrazÃ³w, konwersjÄ™ RGB->Lab, i pakowanie do formatu binarnego. |
| **Soft Encoding** | ğŸŸ¢ **WÅ‚asna implementacja** | Logika zamiany koloru `ab` na rozkÅ‚ad prawdopodobieÅ„stwa na 313 klasach (`ColorEncoder`) zostaÅ‚a napisana rÄ™cznie (znajdowanie sÄ…siadÃ³w, aplikowanie Gaussa, normalizacja). |

## 4. Ewaluacja i Raportowanie

| Element | Status | Opis |
| :--- | :--- | :--- |
| **Metryki (AuC, itp.)** | ğŸŸ¢ **WÅ‚asna implementacja** | Obliczanie *Area Under Curve* dla bÅ‚Ä™du koloryzacji (`calculate_accuracy_auc`) zostaÅ‚o napisane rÄ™cznie przy uÅ¼yciu NumPy, a nie wziÄ™te z biblioteki typu `sklearn.metrics`. |
| **Raportowanie Grupowe** | ğŸŸ¢ **WÅ‚asna inwencja** | CaÅ‚y system mapowania klas ImageNet na grupy semantyczne (np. "Ptaki", "Jedzenie") i generowania raportÃ³w HTML z wykresami skrzypcowymi to nasza autorska warstwa analityczna. |

---

**Podsumowanie:**
Gotowe wziÄ™liÅ›my tylko **"krÄ™gosÅ‚up" (ResNet)** i podstawowe bloki budulcowe (konwolucje, funkcje aktywacji). CaÅ‚a reszta â€“ **sposÃ³b poÅ‚Ä…czenia tych blokÃ³w (Decoder), logika uczenia (Loss), przetwarzanie danych i analityka** â€“ to nasza wÅ‚asna praca inÅ¼ynieryjna i programistyczna.
